{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a336bb0-0c94-4846-a040-e1d33310cde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37fb4047-1ed1-4992-b35f-1d4ae1180ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BONING_PATHS = [\n",
    "    'Theme2/P1/Boning/MVN-J-Boning-64-001.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-90-003.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-90-002.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-90-004.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-64-006.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-64-004.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-64-002.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-90-001.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-64-003.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-79-001.xlsx', \n",
    "    'Theme2/P1/Boning/MVN-J-Boning-64-005.xlsx',\n",
    "    'Theme2/P2/Boning/MVN-S-Boning-89-001.xlsx', \n",
    "    'Theme2/P2/Boning/MVN-S-Boning-89-002.xlsx', \n",
    "    'Theme2/P2/Boning/MVN-S-Boning-89-003.xlsx', \n",
    "    'Theme2/P2/Boning/MVN-S-Boning-76-001.xlsx', \n",
    "    'Theme2/P2/Boning/MVN-S-Boning-63-003.xlsx', \n",
    "    'Theme2/P2/Boning/MVN-S-Boning-63-001.xlsx', \n",
    "    'Theme2/P2/Boning/MVN-S-Boning-76-002.xlsx', \n",
    "    'Theme2/P2/Boning/MVN-S-Boning-63-002.xlsx', \n",
    "    'Theme2/P2/Boning/MVN-S-Boning-89-004.xlsx'\n",
    "]\n",
    "\n",
    "SLICING_PATHS = [\n",
    "    'Theme2/P1/Slicing/MVN-J-Slicing-64-001.xlsx', \n",
    "    'Theme2/P1/Slicing/MVN-J-Slicing-87-001.xlsx', \n",
    "    'Theme2/P1/Slicing/MVN-J-Slicing-73-001.xlsx',\n",
    "    'Theme2/P2/Slicing/MVN-S-Slicing-87-001.xlsx', \n",
    "    'Theme2/P2/Slicing/MVN-S-Slicing-73-001.xlsx', \n",
    "    'Theme2/P2/Slicing/MVN-S-Slicing-63-001.xlsx'\n",
    "]\n",
    "\n",
    "ACCELERATION_SHEETS = [\n",
    "    'Segment Acceleration', \n",
    "    'Segment Angular Acceleration'\n",
    "]\n",
    "\n",
    "boning_class_names = ['Idle', 'Walking', 'Steeling', 'Reaching', 'Cutting', 'Dropping']\n",
    "slicing_class_names = ['Idle', 'Walking', 'Steeling', 'Reaching', 'Cutting', 'Slicing', 'Pulling', 'Placing/Manipulation', 'Dropping']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce134f09-d109-4a1d-a579-82ee9b5c5261",
   "metadata": {},
   "source": [
    "# **Merging the Files into a DataFrame**\n",
    "\n",
    "- merge boning and slicing separately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50186060-0be9-4d69-ab0f-bb13e8586a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# sharpness_levels = [64, 79, 90, 87, 73, 63, 76, 89]\n",
    "\n",
    "# def process_acceleration_data(file_paths, sharpness_levels):\n",
    "#     \"\"\"Process acceleration data from multiple Excel files with different sharpness levels.\"\"\"\n",
    "#     # Dictionary to store processed data by sheet type\n",
    "#     sheet_data = defaultdict(list)\n",
    "    \n",
    "#     # Process all files and extract data by sheet type\n",
    "#     for file_path, sharpness in zip(file_paths, sharpness_levels):\n",
    "#         try:\n",
    "#             xls = pd.ExcelFile(file_path)\n",
    "            \n",
    "#             for sheet_name in xls.sheet_names:\n",
    "#                 if sheet_name not in ACCELERATION_SHEETS:\n",
    "#                     continue\n",
    "                \n",
    "#                 try:\n",
    "#                     # Read the sheet\n",
    "#                     df = pd.read_excel(xls, sheet_name=sheet_name)\n",
    "#                     print(f\"{df.shape}\")\n",
    "                    \n",
    "#                     if df.empty:\n",
    "#                         continue\n",
    "\n",
    "#                     if 'Label' not in df.columns:\n",
    "#                         print(f\"Skipping {sheet_name} since it doesn't have a label column\")\n",
    "#                         continue\n",
    "                    \n",
    "#                     # Add sharpness column\n",
    "#                     df['sharpness'] = sharpness\n",
    "                    \n",
    "#                     # Add sheet name as a column to differentiate data source\n",
    "#                     df['sheet_type'] = sheet_name\n",
    "                    \n",
    "#                     # Add to our collection\n",
    "#                     sheet_data[sheet_name].append(df)\n",
    "                \n",
    "#                 except Exception as e:\n",
    "#                     print(f\"Error processing sheet {file_path} {sheet_name}: {e}\")\n",
    "        \n",
    "#         except Exception as e:\n",
    "#             print(f\"Error processing file {file_path}: {e}\")\n",
    "    \n",
    "#     # Combine data from all files\n",
    "#     combined_dfs = []\n",
    "    \n",
    "#     for sheet_name, dfs in sheet_data.items():\n",
    "#         if dfs:\n",
    "#             # Concatenate all data for this sheet type\n",
    "#             sheet_combined_df = pd.concat(dfs, ignore_index=True)\n",
    "#             combined_dfs.append(sheet_combined_df)\n",
    "    \n",
    "#     # Return combined data frame\n",
    "#     if combined_dfs:\n",
    "#         final_df = pd.concat(combined_dfs, ignore_index=True)\n",
    "#         return final_df\n",
    "    \n",
    "#     return None\n",
    "\n",
    "# def main():\n",
    "#     # Process the data\n",
    "#     merged_df = process_acceleration_data(\n",
    "#         file_paths=SLICING_PATHS,\n",
    "#         sharpness_levels=sharpness_levels\n",
    "#     )\n",
    "    \n",
    "#     if merged_df is None or merged_df.empty:\n",
    "#         print(\"No results generated!\")\n",
    "#         return\n",
    "    \n",
    "#     # Save the final merged dataframe\n",
    "#     output_file = \"slicing_acceleration_data.csv\"\n",
    "#     merged_df.to_csv(output_file, index=False)\n",
    "#     print(f\"Saved data to {output_file} ({merged_df.shape[0]} rows, {merged_df.shape[1]} columns)\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b3893f-9b8c-45ca-9bbd-e07f756cc1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "boning_df = pd.read_csv('boning_acceleration_data.csv')\n",
    "slicing_df = pd.read_csv('slicing_acceleration_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcda5ba6-4eeb-48d7-b808-961ca199c1e7",
   "metadata": {},
   "source": [
    "# **Creating composite features based off XYZ**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab93e287-d57a-4357-afee-d69b85aa2fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_composite_features(df):\n",
    "    \"\"\"\n",
    "    Create composite features from motion capture data - optimized for performance\n",
    "    \"\"\"\n",
    "    # Columns to preserve\n",
    "    preserved_columns = {}\n",
    "    if 'Label' in df.columns:\n",
    "        preserved_columns['Label'] = df['Label']\n",
    "    if 'sharpness' in df.columns:\n",
    "        preserved_columns['sharpness'] = df['sharpness']\n",
    "    \n",
    "    # Get all unique body parts\n",
    "    body_parts = set()\n",
    "    for col in df.columns:\n",
    "        if col.endswith(' x') or col.endswith(' y') or col.endswith(' z'):\n",
    "            body_part = col[:-2]  # Remove the ' x', ' y', or ' z' suffix\n",
    "            body_parts.add(body_part)\n",
    "    \n",
    "    # Dictionary to collect all features\n",
    "    all_features = {}\n",
    "    \n",
    "    # Create aggregated features for each body part\n",
    "    for body_part in body_parts:\n",
    "        # Extract x, y, z components\n",
    "        x_col = f\"{body_part} x\"\n",
    "        y_col = f\"{body_part} y\"\n",
    "        z_col = f\"{body_part} z\"\n",
    "        \n",
    "        # Skip if any component is missing\n",
    "        if not (x_col in df.columns and y_col in df.columns and z_col in df.columns):\n",
    "            continue\n",
    "        \n",
    "        # RMS of x and y (\"mean\")\n",
    "        all_features[f\"{body_part}_mean\"] = np.sqrt((df[x_col]**2 + df[y_col]**2) / 2)\n",
    "        \n",
    "        # RMS of y and z (\"standard deviation\")\n",
    "        all_features[f\"{body_part}_std\"] = np.sqrt((df[y_col]**2 + df[z_col]**2) / 2)\n",
    "        \n",
    "        # RMS of z and x (\"min\")\n",
    "        all_features[f\"{body_part}_min\"] = np.sqrt((df[z_col]**2 + df[x_col]**2) / 2)\n",
    "        \n",
    "        # RMS of x, y, and z (\"max\")\n",
    "        all_features[f\"{body_part}_max\"] = np.sqrt((df[x_col]**2 + df[y_col]**2 + df[z_col]**2) / 3)\n",
    "        \n",
    "        # roll calculation (\"Area under the curve\")\n",
    "        denominator = np.sqrt(df[x_col]**2 + df[z_col]**2)\n",
    "        denominator = np.where(denominator == 0, 1e-10, denominator)\n",
    "        all_features[f\"{body_part}_AUC\"] = 180 * np.arctan2(df[y_col], denominator) / np.pi\n",
    "        \n",
    "        # pitch calculation (\"peaks\")\n",
    "        denominator = np.sqrt(df[y_col]**2 + df[z_col]**2)\n",
    "        denominator = np.where(denominator == 0, 1e-10, denominator)\n",
    "        all_features[f\"{body_part}_peaks\"] = 180 * np.arctan2(df[x_col], denominator) / np.pi\n",
    "    \n",
    "    # Combine preserved columns and features\n",
    "    all_features.update(preserved_columns)\n",
    "    \n",
    "    # Create DataFrame in one go\n",
    "    aggregated_features = pd.DataFrame(all_features)\n",
    "    \n",
    "    return aggregated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f96cbd0b-d00e-4133-9822-57b8e16ac4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "boning_df = create_composite_features(boning_df)\n",
    "slicing_df = create_composite_features(slicing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adb88268-63f5-4f86-9b68-c6f18bd83695",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(357114, 140)\n",
      "(151158, 140)\n"
     ]
    }
   ],
   "source": [
    "print(slicing_df.shape)\n",
    "print(boning_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42a46478-0175-4739-9980-49f99b73d708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  4.,  8.,  2.,  1.,  3.,  5., nan,  7.,  6.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slicing_df['Label'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce73bf-fcbb-4daf-943f-20f0df3fa68d",
   "metadata": {},
   "source": [
    "#### Converting the label values into int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3008eb69-fc7b-4d29-bb48-f17e7c6ecfd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "slicing_df.dropna(inplace=True)\n",
    "slicing_df['Label'] = slicing_df['Label'].round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e84c261-2509-4d4c-a0b6-b8164809c943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([64, 90, 87, 73, 63, 76, 89, 79])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boning_df['sharpness'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58eca40-ed12-4e29-9ec7-dcd577029dae",
   "metadata": {},
   "source": [
    "# **Implementing an Over and Under sampling pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3b02ef3-aca9-49c8-83bc-db7eabacc754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-25 15:51:28.204734: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-04-25 15:51:28.211174: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1745560288.216795   20692 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1745560288.218466   20692 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1745560288.223748   20692 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745560288.223753   20692 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745560288.223754   20692 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1745560288.223755   20692 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-04-25 15:51:28.225578: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "def oversample_data(df):\n",
    "    # 1. Split off train / (val+test)\n",
    "    train_df, temp_df = train_test_split(df, test_size=0.3, stratify=df['Label'], random_state=42)\n",
    "    \n",
    "    # 2. Further split val + test 50/50\n",
    "    val_df, test_df = train_test_split(temp_df, test_size=0.5, stratify=temp_df['Label'], random_state=42)\n",
    "    \n",
    "    # 3. Prepare X and combined target\n",
    "    numeric_cols = train_df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    X = train_df[numeric_cols].copy()\n",
    "    y_combined = (X['Label'].astype(str) + \"_\" + X['sharpness'].astype(str)).values\n",
    "    X = X.drop(columns=['sharpness'])\n",
    "    \n",
    "    # 4. Scale numeric features\n",
    "    numeric_feats = [c for c in X.columns if c != 'Label']\n",
    "    scaler = RobustScaler()\n",
    "    X[numeric_feats] = scaler.fit_transform(X[numeric_feats])\n",
    "    \n",
    "    # 5. Build sampling strategy\n",
    "    counts = Counter(y_combined)\n",
    "    majority = max(counts.values())\n",
    "    target_smote = int(0.5 * majority)\n",
    "    smote_strategy = {cls: target_smote for cls, cnt in counts.items() if cnt < target_smote}\n",
    "    \n",
    "    # 6. Set up SMOTENC + Tomek pipeline\n",
    "    categorical_features = [X.columns.get_loc('Label')]\n",
    "    smote_nc = SMOTENC(categorical_features=categorical_features,\n",
    "                       random_state=42, k_neighbors=15,\n",
    "                       sampling_strategy=smote_strategy)\n",
    "    tomek = TomekLinks(sampling_strategy='all')\n",
    "    pipeline = ImbPipeline([('smote', smote_nc),\n",
    "                            ('undersample', tomek)])\n",
    "    \n",
    "    # 7. Run oversampling\n",
    "    X_resampled, y_resampled = pipeline.fit_resample(X.values, y_combined)\n",
    "    \n",
    "    # 8. Extract just the activity label (before the underscore)\n",
    "    y_activity = np.array([int(lbl.split('_')[0]) for lbl in y_resampled])\n",
    "    \n",
    "    # 9. Build final balanced DataFrame\n",
    "    balanced_df = pd.DataFrame(X_resampled, columns=X.columns)\n",
    "    balanced_df['Label'] = y_activity\n",
    "    \n",
    "    print(\"Balanced class counts:\", Counter(balanced_df['Label']))\n",
    "    return balanced_df, y_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ca62cb-9178-4e54-8b6f-0b9409b04342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced class counts: Counter({4: 114565, 5: 81699, 0: 75300, 2: 75252, 3: 75233, 8: 75160, 7: 56412, 6: 56382, 1: 37676})\n"
     ]
    }
   ],
   "source": [
    "slicing_df_resampled, slicing_df_target = oversample_data(slicing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "678f7264-ef1a-4292-9316-26743ecc61d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced class counts: Counter({4: 88331, 0: 77213, 3: 77205, 2: 77205, 5: 67564, 1: 67533})\n"
     ]
    }
   ],
   "source": [
    "boning_df_resampled, boning_df_target= oversample_data(boning_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b04553f-2454-47e4-801b-1fc6de8ffab2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left Upper Leg_mean</th>\n",
       "      <th>Left Upper Leg_std</th>\n",
       "      <th>Left Upper Leg_min</th>\n",
       "      <th>Left Upper Leg_max</th>\n",
       "      <th>Left Upper Leg_AUC</th>\n",
       "      <th>Left Upper Leg_peaks</th>\n",
       "      <th>Left Shoulder_mean</th>\n",
       "      <th>Left Shoulder_std</th>\n",
       "      <th>Left Shoulder_min</th>\n",
       "      <th>Left Shoulder_max</th>\n",
       "      <th>...</th>\n",
       "      <th>Right Lower Leg_max</th>\n",
       "      <th>Right Lower Leg_AUC</th>\n",
       "      <th>Right Lower Leg_peaks</th>\n",
       "      <th>Right Upper Leg_mean</th>\n",
       "      <th>Right Upper Leg_std</th>\n",
       "      <th>Right Upper Leg_min</th>\n",
       "      <th>Right Upper Leg_max</th>\n",
       "      <th>Right Upper Leg_AUC</th>\n",
       "      <th>Right Upper Leg_peaks</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.284726</td>\n",
       "      <td>-0.231925</td>\n",
       "      <td>0.089892</td>\n",
       "      <td>-0.018087</td>\n",
       "      <td>0.035955</td>\n",
       "      <td>-1.569853</td>\n",
       "      <td>-0.130567</td>\n",
       "      <td>-0.426333</td>\n",
       "      <td>-0.054528</td>\n",
       "      <td>-0.202912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.297593</td>\n",
       "      <td>1.530643</td>\n",
       "      <td>-0.151742</td>\n",
       "      <td>-0.360314</td>\n",
       "      <td>-0.277217</td>\n",
       "      <td>-0.177269</td>\n",
       "      <td>-0.265644</td>\n",
       "      <td>-0.022232</td>\n",
       "      <td>1.629289</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.109006</td>\n",
       "      <td>-0.103915</td>\n",
       "      <td>-0.233245</td>\n",
       "      <td>-0.181927</td>\n",
       "      <td>1.476828</td>\n",
       "      <td>-0.402963</td>\n",
       "      <td>-0.040601</td>\n",
       "      <td>-0.190285</td>\n",
       "      <td>-0.059109</td>\n",
       "      <td>-0.133258</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.361415</td>\n",
       "      <td>1.539473</td>\n",
       "      <td>-0.047313</td>\n",
       "      <td>0.077673</td>\n",
       "      <td>-0.227627</td>\n",
       "      <td>0.005196</td>\n",
       "      <td>-0.093121</td>\n",
       "      <td>-0.058947</td>\n",
       "      <td>1.582495</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.646308</td>\n",
       "      <td>-0.188521</td>\n",
       "      <td>0.225204</td>\n",
       "      <td>0.120314</td>\n",
       "      <td>-0.221487</td>\n",
       "      <td>-1.549615</td>\n",
       "      <td>-0.341190</td>\n",
       "      <td>0.627203</td>\n",
       "      <td>0.620207</td>\n",
       "      <td>0.356889</td>\n",
       "      <td>...</td>\n",
       "      <td>2.969601</td>\n",
       "      <td>-1.529203</td>\n",
       "      <td>-0.119420</td>\n",
       "      <td>0.146027</td>\n",
       "      <td>1.127173</td>\n",
       "      <td>1.136548</td>\n",
       "      <td>0.998823</td>\n",
       "      <td>-0.225158</td>\n",
       "      <td>-0.158989</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.182241</td>\n",
       "      <td>-0.229628</td>\n",
       "      <td>-0.133951</td>\n",
       "      <td>-0.210490</td>\n",
       "      <td>0.589330</td>\n",
       "      <td>1.272732</td>\n",
       "      <td>0.192008</td>\n",
       "      <td>0.480613</td>\n",
       "      <td>0.726121</td>\n",
       "      <td>0.426837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.379448</td>\n",
       "      <td>1.049589</td>\n",
       "      <td>0.723446</td>\n",
       "      <td>0.411960</td>\n",
       "      <td>0.045373</td>\n",
       "      <td>-0.051458</td>\n",
       "      <td>0.024701</td>\n",
       "      <td>1.115945</td>\n",
       "      <td>-0.760511</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.605534</td>\n",
       "      <td>-0.279872</td>\n",
       "      <td>-0.266250</td>\n",
       "      <td>-0.355731</td>\n",
       "      <td>-0.528122</td>\n",
       "      <td>0.486907</td>\n",
       "      <td>-0.236980</td>\n",
       "      <td>-0.186746</td>\n",
       "      <td>-0.360922</td>\n",
       "      <td>-0.279895</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.273899</td>\n",
       "      <td>-1.329104</td>\n",
       "      <td>-0.489319</td>\n",
       "      <td>-0.491241</td>\n",
       "      <td>-0.268551</td>\n",
       "      <td>-0.227822</td>\n",
       "      <td>-0.311845</td>\n",
       "      <td>-0.230050</td>\n",
       "      <td>1.349534</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647674</th>\n",
       "      <td>0.308058</td>\n",
       "      <td>0.235534</td>\n",
       "      <td>0.311056</td>\n",
       "      <td>0.223663</td>\n",
       "      <td>0.195181</td>\n",
       "      <td>0.680874</td>\n",
       "      <td>2.040735</td>\n",
       "      <td>2.222736</td>\n",
       "      <td>1.497207</td>\n",
       "      <td>1.803593</td>\n",
       "      <td>...</td>\n",
       "      <td>0.162290</td>\n",
       "      <td>-0.003999</td>\n",
       "      <td>0.339099</td>\n",
       "      <td>0.356142</td>\n",
       "      <td>1.231473</td>\n",
       "      <td>1.253713</td>\n",
       "      <td>1.120655</td>\n",
       "      <td>-0.304147</td>\n",
       "      <td>-0.049683</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647675</th>\n",
       "      <td>-0.220607</td>\n",
       "      <td>-0.171947</td>\n",
       "      <td>-0.194995</td>\n",
       "      <td>-0.222728</td>\n",
       "      <td>-1.098756</td>\n",
       "      <td>-0.715022</td>\n",
       "      <td>-0.344311</td>\n",
       "      <td>-0.351304</td>\n",
       "      <td>-0.221700</td>\n",
       "      <td>-0.331752</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.284679</td>\n",
       "      <td>-1.645514</td>\n",
       "      <td>-0.032064</td>\n",
       "      <td>-0.643393</td>\n",
       "      <td>-0.283297</td>\n",
       "      <td>-0.295606</td>\n",
       "      <td>-0.371018</td>\n",
       "      <td>0.856277</td>\n",
       "      <td>-0.496406</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647676</th>\n",
       "      <td>0.772762</td>\n",
       "      <td>2.349450</td>\n",
       "      <td>2.259739</td>\n",
       "      <td>2.127046</td>\n",
       "      <td>0.012713</td>\n",
       "      <td>-0.125224</td>\n",
       "      <td>1.954268</td>\n",
       "      <td>1.762731</td>\n",
       "      <td>1.306186</td>\n",
       "      <td>1.583650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.489713</td>\n",
       "      <td>-0.016629</td>\n",
       "      <td>0.613186</td>\n",
       "      <td>-0.054921</td>\n",
       "      <td>0.046583</td>\n",
       "      <td>0.102161</td>\n",
       "      <td>0.027234</td>\n",
       "      <td>0.232923</td>\n",
       "      <td>-0.539752</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647677</th>\n",
       "      <td>0.876826</td>\n",
       "      <td>0.741835</td>\n",
       "      <td>0.837264</td>\n",
       "      <td>0.737750</td>\n",
       "      <td>-0.019240</td>\n",
       "      <td>0.580315</td>\n",
       "      <td>0.580503</td>\n",
       "      <td>0.763853</td>\n",
       "      <td>0.479396</td>\n",
       "      <td>0.549978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.728343</td>\n",
       "      <td>0.389096</td>\n",
       "      <td>-0.131148</td>\n",
       "      <td>0.060713</td>\n",
       "      <td>-0.021909</td>\n",
       "      <td>-0.132707</td>\n",
       "      <td>-0.077750</td>\n",
       "      <td>-1.211637</td>\n",
       "      <td>-0.435618</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647678</th>\n",
       "      <td>-0.227417</td>\n",
       "      <td>0.314996</td>\n",
       "      <td>0.328387</td>\n",
       "      <td>0.216737</td>\n",
       "      <td>0.123083</td>\n",
       "      <td>-0.253782</td>\n",
       "      <td>0.506564</td>\n",
       "      <td>0.877520</td>\n",
       "      <td>0.439598</td>\n",
       "      <td>0.570090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379395</td>\n",
       "      <td>-0.240118</td>\n",
       "      <td>-0.085575</td>\n",
       "      <td>-0.017639</td>\n",
       "      <td>0.166066</td>\n",
       "      <td>0.143592</td>\n",
       "      <td>0.084741</td>\n",
       "      <td>-0.530914</td>\n",
       "      <td>0.185744</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>647679 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Left Upper Leg_mean  Left Upper Leg_std  Left Upper Leg_min  \\\n",
       "0                  0.284726           -0.231925            0.089892   \n",
       "1                 -0.109006           -0.103915           -0.233245   \n",
       "2                  0.646308           -0.188521            0.225204   \n",
       "3                 -0.182241           -0.229628           -0.133951   \n",
       "4                 -0.605534           -0.279872           -0.266250   \n",
       "...                     ...                 ...                 ...   \n",
       "647674             0.308058            0.235534            0.311056   \n",
       "647675            -0.220607           -0.171947           -0.194995   \n",
       "647676             0.772762            2.349450            2.259739   \n",
       "647677             0.876826            0.741835            0.837264   \n",
       "647678            -0.227417            0.314996            0.328387   \n",
       "\n",
       "        Left Upper Leg_max  Left Upper Leg_AUC  Left Upper Leg_peaks  \\\n",
       "0                -0.018087            0.035955             -1.569853   \n",
       "1                -0.181927            1.476828             -0.402963   \n",
       "2                 0.120314           -0.221487             -1.549615   \n",
       "3                -0.210490            0.589330              1.272732   \n",
       "4                -0.355731           -0.528122              0.486907   \n",
       "...                    ...                 ...                   ...   \n",
       "647674            0.223663            0.195181              0.680874   \n",
       "647675           -0.222728           -1.098756             -0.715022   \n",
       "647676            2.127046            0.012713             -0.125224   \n",
       "647677            0.737750           -0.019240              0.580315   \n",
       "647678            0.216737            0.123083             -0.253782   \n",
       "\n",
       "        Left Shoulder_mean  Left Shoulder_std  Left Shoulder_min  \\\n",
       "0                -0.130567          -0.426333          -0.054528   \n",
       "1                -0.040601          -0.190285          -0.059109   \n",
       "2                -0.341190           0.627203           0.620207   \n",
       "3                 0.192008           0.480613           0.726121   \n",
       "4                -0.236980          -0.186746          -0.360922   \n",
       "...                    ...                ...                ...   \n",
       "647674            2.040735           2.222736           1.497207   \n",
       "647675           -0.344311          -0.351304          -0.221700   \n",
       "647676            1.954268           1.762731           1.306186   \n",
       "647677            0.580503           0.763853           0.479396   \n",
       "647678            0.506564           0.877520           0.439598   \n",
       "\n",
       "        Left Shoulder_max  ...  Right Lower Leg_max  Right Lower Leg_AUC  \\\n",
       "0               -0.202912  ...            -0.297593             1.530643   \n",
       "1               -0.133258  ...            -0.361415             1.539473   \n",
       "2                0.356889  ...             2.969601            -1.529203   \n",
       "3                0.426837  ...            -0.379448             1.049589   \n",
       "4               -0.279895  ...            -0.273899            -1.329104   \n",
       "...                   ...  ...                  ...                  ...   \n",
       "647674           1.803593  ...             0.162290            -0.003999   \n",
       "647675          -0.331752  ...            -0.284679            -1.645514   \n",
       "647676           1.583650  ...             0.489713            -0.016629   \n",
       "647677           0.549978  ...             0.728343             0.389096   \n",
       "647678           0.570090  ...             0.379395            -0.240118   \n",
       "\n",
       "        Right Lower Leg_peaks  Right Upper Leg_mean  Right Upper Leg_std  \\\n",
       "0                   -0.151742             -0.360314            -0.277217   \n",
       "1                   -0.047313              0.077673            -0.227627   \n",
       "2                   -0.119420              0.146027             1.127173   \n",
       "3                    0.723446              0.411960             0.045373   \n",
       "4                   -0.489319             -0.491241            -0.268551   \n",
       "...                       ...                   ...                  ...   \n",
       "647674               0.339099              0.356142             1.231473   \n",
       "647675              -0.032064             -0.643393            -0.283297   \n",
       "647676               0.613186             -0.054921             0.046583   \n",
       "647677              -0.131148              0.060713            -0.021909   \n",
       "647678              -0.085575             -0.017639             0.166066   \n",
       "\n",
       "        Right Upper Leg_min  Right Upper Leg_max  Right Upper Leg_AUC  \\\n",
       "0                 -0.177269            -0.265644            -0.022232   \n",
       "1                  0.005196            -0.093121            -0.058947   \n",
       "2                  1.136548             0.998823            -0.225158   \n",
       "3                 -0.051458             0.024701             1.115945   \n",
       "4                 -0.227822            -0.311845            -0.230050   \n",
       "...                     ...                  ...                  ...   \n",
       "647674             1.253713             1.120655            -0.304147   \n",
       "647675            -0.295606            -0.371018             0.856277   \n",
       "647676             0.102161             0.027234             0.232923   \n",
       "647677            -0.132707            -0.077750            -1.211637   \n",
       "647678             0.143592             0.084741            -0.530914   \n",
       "\n",
       "        Right Upper Leg_peaks  Label  \n",
       "0                    1.629289      5  \n",
       "1                    1.582495      4  \n",
       "2                   -0.158989      4  \n",
       "3                   -0.760511      3  \n",
       "4                    1.349534      0  \n",
       "...                       ...    ...  \n",
       "647674              -0.049683      8  \n",
       "647675              -0.496406      8  \n",
       "647676              -0.539752      8  \n",
       "647677              -0.435618      8  \n",
       "647678               0.185744      8  \n",
       "\n",
       "[647679 rows x 139 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slicing_df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "885a9387-27f4-4ddb-a3fb-a3e6ddde5374",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now balanced_df columns: Index(['Left Upper Leg_mean', 'Left Upper Leg_std', 'Left Upper Leg_min',\n",
      "       'Left Upper Leg_max', 'Left Upper Leg_AUC', 'Left Upper Leg_peaks',\n",
      "       'Left Shoulder_mean', 'Left Shoulder_std', 'Left Shoulder_min',\n",
      "       'Left Shoulder_max',\n",
      "       ...\n",
      "       'Right Lower Leg_AUC', 'Right Lower Leg_peaks', 'Right Upper Leg_mean',\n",
      "       'Right Upper Leg_std', 'Right Upper Leg_min', 'Right Upper Leg_max',\n",
      "       'Right Upper Leg_AUC', 'Right Upper Leg_peaks', 'Label', 'sharpness'],\n",
      "      dtype='object', length=140)\n"
     ]
    }
   ],
   "source": [
    "sharpness_resampled = np.array([int(lbl.split('_')[1]) for lbl in boning_df_target])\n",
    "boning_df_resampled['sharpness'] = sharpness_resampled\n",
    "\n",
    "print(\"Now balanced_df columns:\", boning_df_resampled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b69aae81-cfb4-4207-9264-4f3e4c78c113",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now balanced_df columns: Index(['Left Upper Leg_mean', 'Left Upper Leg_std', 'Left Upper Leg_min',\n",
      "       'Left Upper Leg_max', 'Left Upper Leg_AUC', 'Left Upper Leg_peaks',\n",
      "       'Left Shoulder_mean', 'Left Shoulder_std', 'Left Shoulder_min',\n",
      "       'Left Shoulder_max',\n",
      "       ...\n",
      "       'Right Lower Leg_AUC', 'Right Lower Leg_peaks', 'Right Upper Leg_mean',\n",
      "       'Right Upper Leg_std', 'Right Upper Leg_min', 'Right Upper Leg_max',\n",
      "       'Right Upper Leg_AUC', 'Right Upper Leg_peaks', 'Label', 'sharpness'],\n",
      "      dtype='object', length=140)\n"
     ]
    }
   ],
   "source": [
    "sharpness_resampled = np.array([int(lbl.split('_')[1]) for lbl in slicing_df_target])\n",
    "slicing_df_resampled['sharpness'] = sharpness_resampled\n",
    "\n",
    "print(\"Now balanced_df columns:\", slicing_df_resampled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a744e36-498b-4452-bc23-c931d9a702a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Left Upper Leg_mean</th>\n",
       "      <th>Left Upper Leg_std</th>\n",
       "      <th>Left Upper Leg_min</th>\n",
       "      <th>Left Upper Leg_max</th>\n",
       "      <th>Left Upper Leg_AUC</th>\n",
       "      <th>Left Upper Leg_peaks</th>\n",
       "      <th>Left Shoulder_mean</th>\n",
       "      <th>Left Shoulder_std</th>\n",
       "      <th>Left Shoulder_min</th>\n",
       "      <th>Left Shoulder_max</th>\n",
       "      <th>...</th>\n",
       "      <th>Right Lower Leg_AUC</th>\n",
       "      <th>Right Lower Leg_peaks</th>\n",
       "      <th>Right Upper Leg_mean</th>\n",
       "      <th>Right Upper Leg_std</th>\n",
       "      <th>Right Upper Leg_min</th>\n",
       "      <th>Right Upper Leg_max</th>\n",
       "      <th>Right Upper Leg_AUC</th>\n",
       "      <th>Right Upper Leg_peaks</th>\n",
       "      <th>Label</th>\n",
       "      <th>sharpness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.682552</td>\n",
       "      <td>1.868107</td>\n",
       "      <td>1.921719</td>\n",
       "      <td>1.677740</td>\n",
       "      <td>0.101988</td>\n",
       "      <td>-0.297216</td>\n",
       "      <td>0.030683</td>\n",
       "      <td>0.377830</td>\n",
       "      <td>0.511702</td>\n",
       "      <td>0.279764</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186578</td>\n",
       "      <td>-1.366432</td>\n",
       "      <td>1.507616</td>\n",
       "      <td>0.879217</td>\n",
       "      <td>1.185366</td>\n",
       "      <td>1.024399</td>\n",
       "      <td>0.255722</td>\n",
       "      <td>0.782468</td>\n",
       "      <td>4</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.505051</td>\n",
       "      <td>1.855258</td>\n",
       "      <td>1.910049</td>\n",
       "      <td>1.724229</td>\n",
       "      <td>-0.323153</td>\n",
       "      <td>0.421996</td>\n",
       "      <td>-0.095532</td>\n",
       "      <td>0.273851</td>\n",
       "      <td>0.162196</td>\n",
       "      <td>0.082272</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.210508</td>\n",
       "      <td>-0.532834</td>\n",
       "      <td>0.096416</td>\n",
       "      <td>0.267077</td>\n",
       "      <td>0.159033</td>\n",
       "      <td>0.148522</td>\n",
       "      <td>0.711889</td>\n",
       "      <td>-0.018835</td>\n",
       "      <td>3</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.400196</td>\n",
       "      <td>0.002230</td>\n",
       "      <td>-0.036756</td>\n",
       "      <td>0.020019</td>\n",
       "      <td>-1.076554</td>\n",
       "      <td>0.885334</td>\n",
       "      <td>-0.293377</td>\n",
       "      <td>-0.281998</td>\n",
       "      <td>-0.305526</td>\n",
       "      <td>-0.329494</td>\n",
       "      <td>...</td>\n",
       "      <td>1.213678</td>\n",
       "      <td>0.418630</td>\n",
       "      <td>-0.158919</td>\n",
       "      <td>-0.122539</td>\n",
       "      <td>-0.075082</td>\n",
       "      <td>-0.144367</td>\n",
       "      <td>-0.118274</td>\n",
       "      <td>-0.876630</td>\n",
       "      <td>4</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.051740</td>\n",
       "      <td>0.389138</td>\n",
       "      <td>0.603739</td>\n",
       "      <td>0.514494</td>\n",
       "      <td>-0.419779</td>\n",
       "      <td>0.956311</td>\n",
       "      <td>-0.224322</td>\n",
       "      <td>-0.149276</td>\n",
       "      <td>-0.076307</td>\n",
       "      <td>-0.188293</td>\n",
       "      <td>...</td>\n",
       "      <td>1.691733</td>\n",
       "      <td>-0.122938</td>\n",
       "      <td>0.306982</td>\n",
       "      <td>1.297898</td>\n",
       "      <td>1.340874</td>\n",
       "      <td>1.142689</td>\n",
       "      <td>-0.066496</td>\n",
       "      <td>0.277738</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.656197</td>\n",
       "      <td>1.822196</td>\n",
       "      <td>1.605164</td>\n",
       "      <td>1.594355</td>\n",
       "      <td>0.558811</td>\n",
       "      <td>0.137996</td>\n",
       "      <td>1.900449</td>\n",
       "      <td>1.011318</td>\n",
       "      <td>2.097873</td>\n",
       "      <td>1.595336</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>-0.112879</td>\n",
       "      <td>-0.282371</td>\n",
       "      <td>0.525813</td>\n",
       "      <td>0.508743</td>\n",
       "      <td>0.389567</td>\n",
       "      <td>-0.131860</td>\n",
       "      <td>0.094690</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Left Upper Leg_mean  Left Upper Leg_std  Left Upper Leg_min  \\\n",
       "0             0.682552            1.868107            1.921719   \n",
       "1             1.505051            1.855258            1.910049   \n",
       "2             0.400196            0.002230           -0.036756   \n",
       "3             1.051740            0.389138            0.603739   \n",
       "4             1.656197            1.822196            1.605164   \n",
       "\n",
       "   Left Upper Leg_max  Left Upper Leg_AUC  Left Upper Leg_peaks  \\\n",
       "0            1.677740            0.101988             -0.297216   \n",
       "1            1.724229           -0.323153              0.421996   \n",
       "2            0.020019           -1.076554              0.885334   \n",
       "3            0.514494           -0.419779              0.956311   \n",
       "4            1.594355            0.558811              0.137996   \n",
       "\n",
       "   Left Shoulder_mean  Left Shoulder_std  Left Shoulder_min  \\\n",
       "0            0.030683           0.377830           0.511702   \n",
       "1           -0.095532           0.273851           0.162196   \n",
       "2           -0.293377          -0.281998          -0.305526   \n",
       "3           -0.224322          -0.149276          -0.076307   \n",
       "4            1.900449           1.011318           2.097873   \n",
       "\n",
       "   Left Shoulder_max  ...  Right Lower Leg_AUC  Right Lower Leg_peaks  \\\n",
       "0           0.279764  ...             0.186578              -1.366432   \n",
       "1           0.082272  ...            -1.210508              -0.532834   \n",
       "2          -0.329494  ...             1.213678               0.418630   \n",
       "3          -0.188293  ...             1.691733              -0.122938   \n",
       "4           1.595336  ...             0.000526              -0.112879   \n",
       "\n",
       "   Right Upper Leg_mean  Right Upper Leg_std  Right Upper Leg_min  \\\n",
       "0              1.507616             0.879217             1.185366   \n",
       "1              0.096416             0.267077             0.159033   \n",
       "2             -0.158919            -0.122539            -0.075082   \n",
       "3              0.306982             1.297898             1.340874   \n",
       "4             -0.282371             0.525813             0.508743   \n",
       "\n",
       "   Right Upper Leg_max  Right Upper Leg_AUC  Right Upper Leg_peaks  Label  \\\n",
       "0             1.024399             0.255722               0.782468      4   \n",
       "1             0.148522             0.711889              -0.018835      3   \n",
       "2            -0.144367            -0.118274              -0.876630      4   \n",
       "3             1.142689            -0.066496               0.277738      1   \n",
       "4             0.389567            -0.131860               0.094690      4   \n",
       "\n",
       "   sharpness  \n",
       "0         87  \n",
       "1         90  \n",
       "2         90  \n",
       "3         90  \n",
       "4         79  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boning_df_resampled.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10093b6c-99bc-4d7b-b0d5-2ffa6a208d4a",
   "metadata": {},
   "source": [
    "# **Model Comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7efa0e4-8b65-4efc-a76a-359ad905b644",
   "metadata": {},
   "source": [
    "### **Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "670019c7-d6db-4cd2-ac9c-96de7ce6ee2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "def RFM(df):\n",
    "    X = df.iloc[:, :138]\n",
    "    y = df.iloc[:, -2]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    clf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Classification Report:\")\n",
    "    print(report)\n",
    "\n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1248c70e-983f-49b0-8bab-330afd513679",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 73.84%\n",
      "Confusion Matrix:\n",
      "[[20004    88   507   390   803   221    25   116   328]\n",
      " [   54 11216     1     4     4     0     0     2     3]\n",
      " [  799    87 18976   475  1379   335    27   168   390]\n",
      " [  391    22    46 19490  1270   359    30   504   630]\n",
      " [ 1451    79  1034  2011 23107  3541   185  1017  2004]\n",
      " [  789    28   730  1091 10434  9517   128   715   999]\n",
      " [  135    13    78   537  2317   589 12487   347   379]\n",
      " [  202     9    30   628  1919   490    33 13049   617]\n",
      " [  828    39   175  1542  2978   606    41   606 15626]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85     22482\n",
      "           1       0.97      0.99      0.98     11284\n",
      "           2       0.88      0.84      0.86     22636\n",
      "           3       0.74      0.86      0.80     22742\n",
      "           4       0.52      0.67      0.59     34429\n",
      "           5       0.61      0.39      0.47     24431\n",
      "           6       0.96      0.74      0.84     16882\n",
      "           7       0.79      0.77      0.78     16977\n",
      "           8       0.74      0.70      0.72     22441\n",
      "\n",
      "    accuracy                           0.74    194304\n",
      "   macro avg       0.78      0.76      0.76    194304\n",
      "weighted avg       0.75      0.74      0.74    194304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RFM_slicing_accuracy, RFM_slicing_report = RFM(slicing_df_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "14d0eb68-ea0e-4293-8bcb-fb1362aa48d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 89.12%\n",
      "Confusion Matrix:\n",
      "[[19718   819  1239   331   623   229]\n",
      " [  391 19111   134   313   283   192]\n",
      " [  861   498 20266   502   967   228]\n",
      " [  196   405   278 21380   639   108]\n",
      " [  631   509  1043  1012 22766   436]\n",
      " [  366   459   163   288   714 18418]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.86      0.87     22959\n",
      "           1       0.88      0.94      0.91     20424\n",
      "           2       0.88      0.87      0.87     23322\n",
      "           3       0.90      0.93      0.91     23006\n",
      "           4       0.88      0.86      0.87     26397\n",
      "           5       0.94      0.90      0.92     20408\n",
      "\n",
      "    accuracy                           0.89    136516\n",
      "   macro avg       0.89      0.89      0.89    136516\n",
      "weighted avg       0.89      0.89      0.89    136516\n",
      "\n"
     ]
    }
   ],
   "source": [
    "RFM_boning_accuracy, RFM_boning_report = RFM(boning_df_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934daf8f-793f-4b2b-9838-d25ecee27fbc",
   "metadata": {},
   "source": [
    "### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e88f75d8-4ecf-4d27-a334-f35d095b872c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def LRM(df):\n",
    "    X = df.iloc[:, :138]\n",
    "    y = df.iloc[:, -2]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    log_reg = LogisticRegression(max_iter=500)\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "\n",
    "    print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(cm)\n",
    "    print(\"Logistic Regression:\")\n",
    "    print(report)\n",
    "\n",
    "    return accuracy, report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "58c902f1-7a9a-48c2-b7ff-50e440d1086a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 46.83%\n",
      "Confusion Matrix:\n",
      "[[11202  1900  5837  1495  1341  1184]\n",
      " [ 4265 10479  1052  2593   722  1313]\n",
      " [ 5202  1104 13381   949  2056   630]\n",
      " [ 3349  3039  3186  8975  2702  1755]\n",
      " [ 2512   996  4734  2209 14810  1136]\n",
      " [ 4343  2891  3031  3123  1943  5077]]\n",
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.36      0.49      0.42     22959\n",
      "           1       0.51      0.51      0.51     20424\n",
      "           2       0.43      0.57      0.49     23322\n",
      "           3       0.46      0.39      0.42     23006\n",
      "           4       0.63      0.56      0.59     26397\n",
      "           5       0.46      0.25      0.32     20408\n",
      "\n",
      "    accuracy                           0.47    136516\n",
      "   macro avg       0.48      0.46      0.46    136516\n",
      "weighted avg       0.48      0.47      0.46    136516\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notvisal/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "LRM_boning_accuracy, LRM_boning_report = LRM(boning_df_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b30c0b09-74b8-4f8e-9103-58b0c1e73264",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notvisal/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 31.21%\n",
      "Confusion Matrix:\n",
      "[[ 8801  1622  5411  1358  3997    30   239   210   814]\n",
      " [ 2066  7598  1110   139   268     0    33    48    22]\n",
      " [ 3092   389 13238   810  4186    89   224   166   442]\n",
      " [ 3572   312  1434  5893  8672    81   430   621  1727]\n",
      " [ 3881   530  5055  2327 18294   754  1193   848  1547]\n",
      " [ 2603   272  3756  1235 13476   690   936   572   891]\n",
      " [ 1727   116  2455  1042  8951   204  1588   345   454]\n",
      " [ 1801   150  1048  1525  9068   157   488  1487  1253]\n",
      " [ 4183   414  1736  2820  9064    92   507   580  3045]]\n",
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.39      0.32     22482\n",
      "           1       0.67      0.67      0.67     11284\n",
      "           2       0.38      0.58      0.46     22636\n",
      "           3       0.34      0.26      0.30     22742\n",
      "           4       0.24      0.53      0.33     34429\n",
      "           5       0.33      0.03      0.05     24431\n",
      "           6       0.28      0.09      0.14     16882\n",
      "           7       0.30      0.09      0.14     16977\n",
      "           8       0.30      0.14      0.19     22441\n",
      "\n",
      "    accuracy                           0.31    194304\n",
      "   macro avg       0.35      0.31      0.29    194304\n",
      "weighted avg       0.32      0.31      0.28    194304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "LRM_slicing_accuracy, LRM_slicing_report = LRM(slicing_df_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d731be-b375-4797-8087-5c614234cb58",
   "metadata": {},
   "source": [
    "### **Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f6632460-8e1d-452d-a6d7-b848a75b6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "def fast_linear_svm(df):\n",
    "    X = df.iloc[:, :138]\n",
    "    y = df.iloc[:, -2]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "    clf = make_pipeline(\n",
    "        StandardScaler(),\n",
    "        LinearSVC(dual=False,\n",
    "                  C=1.0,\n",
    "                  max_iter=10_000,\n",
    "                  random_state=42)\n",
    "    )\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print(\"Test Accuracy: {:.2f}%\".format(accuracy_score(y_test, y_pred) * 100))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "654dabd7-5552-498d-9914-eab5f00b2d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_model_boning = fast_linear_svm(boning_df_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "21c7042b-5f72-48a3-a309-24560828cee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# svm_model_slicing = fast_linear_svm(slicing_df_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b00eb9-19fb-4c69-b902-1eb04fc20a18",
   "metadata": {},
   "source": [
    "### **LSTM-CNN Hybrid**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ea78b739-562b-4ca4-a615-3412277f30fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dropout, LSTM, Conv1D, MaxPool1D, GlobalAveragePooling1D, BatchNormalization, Dense, Activation, Reshape\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Title: Human Activity Recognition using LSTM-CNN\n",
    "# Author: Tanmay Chauhan\n",
    "# Date: July 9th, 2022\n",
    "# Availability: https://medium.com/@tanmaychauhan111/human-activity-recognition-using-lstm-cnn-8ccb1a42cb81\n",
    "\n",
    "def model_init(time_steps: int, num_classes: int):\n",
    "    model = Sequential([\n",
    "        LSTM(64, return_sequences=True,\n",
    "             input_shape=(time_steps, 1),\n",
    "             activation='relu',\n",
    "             kernel_regularizer=l2(1e-4)),\n",
    "        Dropout(0.1),\n",
    "\n",
    "        LSTM(64, return_sequences=True,\n",
    "             activation='relu',\n",
    "             kernel_regularizer=l2(1e-4)),\n",
    "        Dropout(0.1),\n",
    "\n",
    "        Conv1D(64, kernel_size=2, strides=2,\n",
    "               activation='relu',\n",
    "               kernel_regularizer=l2(1e-4)),\n",
    "        Dropout(0.1),\n",
    "\n",
    "        MaxPool1D(pool_size=4, padding='same'),\n",
    "        Conv1D(192, kernel_size=2, strides=1,\n",
    "               activation='relu',\n",
    "               kernel_regularizer=l2(1e-4)),\n",
    "        GlobalAveragePooling1D(),\n",
    "        Dropout(0.1),\n",
    "        BatchNormalization(epsilon=1e-6),\n",
    "\n",
    "        Dense(num_classes,\n",
    "              activation='softmax',\n",
    "              kernel_regularizer=l2(1e-4))\n",
    "    ])\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4, clipnorm=1.0), #added gradient clipping\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d2571229-e973-4ed6-8e10-7b068a498acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "def train_activity_on_LSTMCNN(df, *,\n",
    "                              model: tf.keras.Model,\n",
    "                              test_size=0.2,\n",
    "                              val_split=0.1,\n",
    "                              epochs=50,\n",
    "                              batch_size=128,\n",
    "                              patience=4,\n",
    "                              random_state=42):\n",
    "    train_df, test_df = train_test_split(\n",
    "        df, \n",
    "        test_size=test_size,\n",
    "        stratify=df['Label'],\n",
    "        random_state=random_state\n",
    "    )\n",
    "    \n",
    "    # not counting 'Label' and 'sharpness' columns into the time_steps\n",
    "    time_steps = train_df.shape[1] - 2\n",
    "\n",
    "    X_train_raw = train_df.drop(columns=['sharpness', 'Label']).values\n",
    "    y_train = train_df['Label'].values\n",
    "\n",
    "    X_test_raw = test_df.drop(columns=['sharpness', 'Label']).values\n",
    "    y_test = test_df['Label'].values\n",
    "\n",
    "    # scaling features\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train_raw)\n",
    "    X_test_scaled = scaler.fit_transform(X_test_raw)\n",
    "\n",
    "    # Reshape to 3D for LSTM-CNN model\n",
    "    X_train = X_train_scaled.reshape(-1, time_steps, 1)\n",
    "    X_test = X_test_scaled.reshape(-1, time_steps, 1)\n",
    "\n",
    "    assert np.isfinite(X_train_scaled).all()\n",
    "    assert not np.isnan(y_train).any()\n",
    "\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        restore_best_weights=True\n",
    "    )\n",
    "    \n",
    "    # fit with validation split\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_split=val_split,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # evaluate on test set\n",
    "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test Accuracy: {test_acc*100:.2f}%\")\n",
    "\n",
    "    return history, test_loss, test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b6b606c7-6063-4647-93b4-1b0978029674",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/notvisal/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">16,896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">138</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">18</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,768</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling1D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,158</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm_13 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m138\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m16,896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_23 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m138\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_14 (\u001b[38;5;33mLSTM\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m138\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │        \u001b[38;5;34m33,024\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_24 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m138\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_12 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_25 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m69\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling1d_6 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m18\u001b[0m, \u001b[38;5;34m64\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv1d_13 (\u001b[38;5;33mConv1D\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m192\u001b[0m)        │        \u001b[38;5;34m24,768\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling1d_5      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling1D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_26 (\u001b[38;5;33mDropout\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)            │           \u001b[38;5;34m768\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)              │         \u001b[38;5;34m1,158\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,870</span> (331.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m84,870\u001b[0m (331.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">84,486</span> (330.02 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m84,486\u001b[0m (330.02 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> (1.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m384\u001b[0m (1.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m2276/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 17ms/step - accuracy: 0.2720 - loss: 1.7568 - val_accuracy: 0.3361 - val_loss: 1.6304\n",
      "Epoch 2/50\n",
      "\u001b[1m2276/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.3592 - loss: 1.6054 - val_accuracy: 0.3819 - val_loss: 1.5630\n",
      "Epoch 3/50\n",
      "\u001b[1m2276/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 15ms/step - accuracy: 0.4012 - loss: 1.5218 - val_accuracy: 0.4113 - val_loss: 1.4794\n",
      "Epoch 4/50\n",
      "\u001b[1m2276/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.4245 - loss: 1.4763 - val_accuracy: 0.4105 - val_loss: 1.4790\n",
      "Epoch 5/50\n",
      "\u001b[1m2276/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.4399 - loss: 1.4424 - val_accuracy: 0.4220 - val_loss: 1.4483\n",
      "Epoch 6/50\n",
      "\u001b[1m2276/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.4551 - loss: 1.4143 - val_accuracy: 0.4531 - val_loss: 1.3886\n",
      "Epoch 7/50\n",
      "\u001b[1m2276/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.4696 - loss: 1.3820 - val_accuracy: 0.4758 - val_loss: 1.3544\n",
      "Epoch 8/50\n",
      "\u001b[1m2276/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.4779 - loss: 1.3618 - val_accuracy: 0.4566 - val_loss: 1.4024\n",
      "Epoch 9/50\n",
      "\u001b[1m2276/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 15ms/step - accuracy: 0.4907 - loss: 1.3371 - val_accuracy: 0.5054 - val_loss: 1.2971\n",
      "Epoch 10/50\n",
      "\u001b[1m1792/2276\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.4982 - loss: 1.3225"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[63]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      2\u001b[39m num_classes = \u001b[38;5;28mlen\u001b[39m(np.unique(boning_df_resampled[\u001b[33m'\u001b[39m\u001b[33mLabel\u001b[39m\u001b[33m'\u001b[39m]) - \u001b[32m2\u001b[39m)\n\u001b[32m      4\u001b[39m model = model_init(time_steps, num_classes)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m boning_history, boning_test_loss, boning_test_acc = \u001b[43mtrain_activity_on_LSTMCNN\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mboning_df_resampled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_split\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpatience\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[62]\u001b[39m\u001b[32m, line 47\u001b[39m, in \u001b[36mtrain_activity_on_LSTMCNN\u001b[39m\u001b[34m(df, model, test_size, val_split, epochs, batch_size, patience, random_state)\u001b[39m\n\u001b[32m     40\u001b[39m early_stopping = EarlyStopping(\n\u001b[32m     41\u001b[39m     monitor=\u001b[33m'\u001b[39m\u001b[33mval_loss\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     42\u001b[39m     patience=patience,\n\u001b[32m     43\u001b[39m     restore_best_weights=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m     44\u001b[39m )\n\u001b[32m     46\u001b[39m \u001b[38;5;66;03m# fit with validation split\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m history = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_split\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     52\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m     54\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# evaluate on test set\u001b[39;00m\n\u001b[32m     57\u001b[39m test_loss, test_acc = model.evaluate(X_test, y_test, verbose=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:117\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    115\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m117\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:371\u001b[39m, in \u001b[36mTensorFlowTrainer.fit\u001b[39m\u001b[34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[39m\n\u001b[32m    369\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    370\u001b[39m     callbacks.on_train_batch_begin(step)\n\u001b[32m--> \u001b[39m\u001b[32m371\u001b[39m     logs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    372\u001b[39m     callbacks.on_train_batch_end(step, logs)\n\u001b[32m    373\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stop_training:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py:219\u001b[39m, in \u001b[36mTensorFlowTrainer._make_function.<locals>.function\u001b[39m\u001b[34m(iterator)\u001b[39m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfunction\u001b[39m(iterator):\n\u001b[32m    216\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[32m    217\u001b[39m         iterator, (tf.data.Iterator, tf.distribute.DistributedIterator)\n\u001b[32m    218\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         opt_outputs = \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    220\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs.has_value():\n\u001b[32m    221\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    148\u001b[39m filtered_tb = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m150\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    152\u001b[39m   filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[39m, in \u001b[36mFunction.__call__\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    830\u001b[39m compiler = \u001b[33m\"\u001b[39m\u001b[33mxla\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mnonXla\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    832\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m._jit_compile):\n\u001b[32m--> \u001b[39m\u001b[32m833\u001b[39m   result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    835\u001b[39m new_tracing_count = \u001b[38;5;28mself\u001b[39m.experimental_get_tracing_count()\n\u001b[32m    836\u001b[39m without_tracing = (tracing_count == new_tracing_count)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[39m, in \u001b[36mFunction._call\u001b[39m\u001b[34m(self, *args, **kwds)\u001b[39m\n\u001b[32m    875\u001b[39m \u001b[38;5;28mself\u001b[39m._lock.release()\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m results = \u001b[43mtracing_compilation\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[32m    880\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    881\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._created_variables:\n\u001b[32m    882\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCreating variables on a non-first call to a function\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    883\u001b[39m                    \u001b[33m\"\u001b[39m\u001b[33m decorated with tf.function.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[39m, in \u001b[36mcall_function\u001b[39m\u001b[34m(args, kwargs, tracing_options)\u001b[39m\n\u001b[32m    137\u001b[39m bound_args = function.function_type.bind(*args, **kwargs)\n\u001b[32m    138\u001b[39m flat_inputs = function.function_type.unpack_inputs(bound_args)\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[32m    140\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[32m    141\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1322\u001b[39m, in \u001b[36mConcreteFunction._call_flat\u001b[39m\u001b[34m(self, tensor_inputs, captured_inputs)\u001b[39m\n\u001b[32m   1318\u001b[39m possible_gradient_type = gradients_util.PossibleTapeGradientTypes(args)\n\u001b[32m   1319\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type == gradients_util.POSSIBLE_GRADIENT_TYPES_NONE\n\u001b[32m   1320\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[32m   1321\u001b[39m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1322\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_inference_function\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1323\u001b[39m forward_backward = \u001b[38;5;28mself\u001b[39m._select_forward_and_backward_functions(\n\u001b[32m   1324\u001b[39m     args,\n\u001b[32m   1325\u001b[39m     possible_gradient_type,\n\u001b[32m   1326\u001b[39m     executing_eagerly)\n\u001b[32m   1327\u001b[39m forward_function, args_with_tangents = forward_backward.forward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[39m, in \u001b[36mAtomicFunction.call_preflattened\u001b[39m\u001b[34m(self, args)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core.Tensor]) -> Any:\n\u001b[32m    215\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m   flat_outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.function_type.pack_output(flat_outputs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[39m, in \u001b[36mAtomicFunction.call_flat\u001b[39m\u001b[34m(self, *args)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m record.stop_recording():\n\u001b[32m    250\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._bound_context.executing_eagerly():\n\u001b[32m--> \u001b[39m\u001b[32m251\u001b[39m     outputs = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_bound_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    253\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    255\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     outputs = make_call_op_in_graph(\n\u001b[32m    258\u001b[39m         \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m._bound_context.function_call_options.as_attrs(),\n\u001b[32m    261\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/tensorflow/python/eager/context.py:1688\u001b[39m, in \u001b[36mContext.call_function\u001b[39m\u001b[34m(self, name, tensor_inputs, num_outputs)\u001b[39m\n\u001b[32m   1686\u001b[39m cancellation_context = cancellation.context()\n\u001b[32m   1687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1688\u001b[39m   outputs = \u001b[43mexecute\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1689\u001b[39m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1690\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1691\u001b[39m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1692\u001b[39m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1693\u001b[39m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1694\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1695\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1696\u001b[39m   outputs = execute.execute_with_cancellation(\n\u001b[32m   1697\u001b[39m       name.decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   1698\u001b[39m       num_outputs=num_outputs,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1702\u001b[39m       cancellation_manager=cancellation_context,\n\u001b[32m   1703\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.12.3/envs/InternEnv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = \u001b[43mpywrap_tfe\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     54\u001b[39m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "time_steps = boning_df_resampled.shape[1] - 2\n",
    "num_classes = len(np.unique(boning_df_resampled['Label']) - 2)\n",
    "\n",
    "model = model_init(time_steps, num_classes)\n",
    "\n",
    "boning_history, boning_test_loss, boning_test_acc = train_activity_on_LSTMCNN(\n",
    "    boning_df_resampled,\n",
    "    model=model,\n",
    "    test_size=0.2,\n",
    "    val_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=128,\n",
    "    patience=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e874e4-df73-44f5-9cf2-8dae415961d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
